

This set of cases is a collection of preliminary tests used to determine what ember injection configuration to use for the ember paper cases, in some sense it was figuring out what wouldn't work or what could work but would need a lot of extra work to improve the methods to be useful. See the ember paper cases for the final ember injection configuration used for the ember paper. As such, the original cases these cases were taken from did NOT originally get run for all configurations shown here, there is enough variety in the configurations that trying them all might not be a good idea without setting up some kind of automating scripts to aide in processing multiple repeated cases where the cases are all the same but only varying in small things for each case. Each wind field is unique, but the particle simulations are in essence just a copy and paste, adjusting for the given input wind field, it would have been preferred not to have so many copies of similar particle simulations but as it makes it easier to keep track of simulations by grouping them by each separate wind simulation, it seemed to be the right way to go to organize these cases.

Be that as it may, the first particle simulations were mostly just run at the 20 mph wind speed, some of them with no fence present, some with fence present, just for a single configuration or two. This was partially because it was quickly discovered that the ember sizes and density were too big for embers to reach the desired distances from injection, it is better to focus on multiple simulations of the lower density and lower ember size configurations.



The first particle simulations done were the /burningTreeStands/ cases, the original configuration being done with no fence present, done at 20 mph, with 45 degree angled injections, with 300 kg/m^3 particle density, doing one case with all the injection models at once then a separate case for each individual injection model. Then a later attempt to repeat the simulations with 35 degrees, 40 degrees, 50 degrees, and 55 degrees at the various 5 mph and 60 mph wind speeds was attempted, but it turned out to be a bit much to simulate without doing some kind of automation, we moved on to more important simulations and the later simulation ideas were only very partially done.
The idea behind these simulations was to represent stands or single trees/bushes of burning vegetation in atmospheric flows, in essence trying to convert the IBHS injections to a form that could be used with the log profile winds required for our ember paper cases, picking and adjusting the injections while making various assumptions about the size of the crowning flame, plume, and plume angle that would be seen under the ambient winds in an attempt to more accurately represent actual stands or single trees/bushes of burning vegetation than was done in the IBHS case. It was desired to use these tree stands as direct injections to a fence case, to first test how they would work before adding in a fence to the flows, to see how far particles would go to be able to know the optimal location within the domain to place the burning stands to cause the embers to pass through the fence instead of missing the fence. When it became apparent that the particle trajectories would change with any alteration of wind speed, ember density, or ember size, also that sometimes the required distance between the injection and the fence could be greater than the domain could be sized for some cases, the plan shifted to see if there might be a way to use these particle simulations to derive a new injection type that would consist of how embers pass through the boundary regions of a smaller domain downwind of the burning stands, to be used as an injection for domains that didn't have enough space upwind to directly place the burning stands. The new injection type would essentially be like taking slices of the plume from the first simulation at some specific time at some specific distance and height downwind, using the slices of particle information as an injection at the boundaries of a new simulation with a smaller domain downwind of the burning vegetation. Note that it wouldn't be just a slice, not  exactly, it would need to check when particles passed through the slice locations at the desired time or times, figuring out what particle locations, sizes, trajectories (angles and velocities) and other par info the particles had as they passed through a given slice location.
It was quickly apparent that the embers were falling to the ground rather quickly. Also that the incoming trajectories of the embers to the fence would change with any alteration of wind speed, ember density, or ember size, meaning that the trajectories of how they would hit a fence, or a domain downwind in the flow, would change for many of our desired variable parameters. This would not match well with the idea of choosing a single source for all simulations, unless the type of patch or single tree were set in size but moved around to a new position upwind or downwind of the fence for each change in variable, making it a trial and error experience to get the source location correct. Plus, this wouldn't guarantee particles actually would go through the fence, in some cases they could end up going over the fence instead because the trajectories tended to be cannon-like into the air rather than a long slow horizontal falling pattern.

Because embers were falling to the ground rather quickly, it was surmised that it was possible that there were missing physics with the solver, causing particles to not have quite enough lift. Even if there were no missing physics for the solver, like if the wind field conditions and particle properties (size, shape, density) used by our simulations were just conditions that resulted in short to medium range spotting embers (100's of m) instead of long range spotting embers (up to 7 miles), there could definitely be a disconnect in physics if the incoming injections were derived from different physics than those of the solver. For example, if particles technically travelled in 60 mph winds in their injection derivation simulation, but then were injected into a simulation with 20 mph winds, they would begin to drop quite fast in the 20 mph winds compared to how fast they were dropping in the 60 mph simulation. Another example would be if embers started a trajectory at one set of flow conditions (pre-injection, say ember storms are technically long range spotting physics with trajectories of up to 7 miles, particles seeming to ride with more lift in the wind), then rapidly switched to another set of flow conditions (post-injection, our models seemed to only be able to do short range to medium range spotting physics with trajectories of up to 100's of meters), embers would be riding along in the wind up till injection where they fall out much sooner than if they were to continue to ride along the wind and fall out slower. This is an important finding, though there wasn't much we could do about it other than note it, and try to avoid any additional disconnects as much as possible in deriving our new injection type. To avoid accidentally adding additional disconnects like this, to minimize this type of disconnect as much as possible, this means that any derived new injection type for a smaller domain downwind of the burning vegetation stands needs to match wind and turbulence fields between the two simulations for all regions of flow where particles travel leading up to the new injection type injection location. The wind and turbulence fields seem to match the same between simulations of the same condition, without and with a fence, IF embers from one simulation are injected into another far enough upwind of the fence. But as the wind and turbulence fields are altered for some distance upwind of the fence, not just downwind of the fence, it seems like the fence in the flow could cause a limit to how close to the fence particles could be injected with the new injection type.
In the end, we ended up moving on to use simpler injection methods before we accomplished deriving this new injection type, but I wanted to add the documentation here in case it becomes a future project idea. Anyhow, in an attempt to describe this concept of disconnects in particle trajectories caused by doing two simulations with differing particle physics, some hand drawings were made with the disconnect between the physics occuring right at the point where particles reached their peak height and slowed before they were to begin dropping again. Examples included embers floating along in the wind high up in the air from long range spotting, where the particles might normally continue on or fall a bit slower if they continued on with the same physics, but a new line was added showing how they would drop almost instantanously if they switched physics to short range spotting physics while still riding in the air. Another set of examples included particles launched into the air into a 60 mph wind field, how the trajectory would look if the particles continued on in the 60 mph wind field till the end, then a line was added showing how particles would start to drop in a separate sooner trajectory if the wind field somehow instantaneously changed to 20 mph midway through the 60 mph trajectory. This led to pondering whether particles of smaller density or size could represent particles simulated using the longer range spotting physics, like how similar would the various trajectories be, could long range spotting be emulated by using smaller and lighter particles?

Anyhow, the goal of these simulations ended up shifting in focus yet again to attempt to simulate these hand drawn drawings, cutting the side view pictures of the simulations in half at various locations and times and putting cut pictures from two separate physics simulations together along where they were cut to form new mixed physics simulation pictures. This was surprisingly a pain in the butt, but it led to finding out that the trajectory of the particles for a given slice could be completely different depending on how far along their trajectory path they were when doing the slice. So particles sliced before the peak height would have an upward angle, higher velocity but slowing, the angle starting to get less steep, the angle being less and less steep if the slice were taken a bit further along before reaching the peak height. Particles from slices at the peak height were horizontal, or slightly tilting up or down, with near zero vertical velocity but still reaching the horizontal velocity of the ambient flow. Particles from slices from beyond the peak height started to tilt more and more towards the ground in angle, and to achieve greater and greater velocities. So it turned out that even when keeping simulation physics the same throughout the entire simulation, the choice of velocity and angle of particles used from one simulation as a source for another simulation ended up depending more on where in the particle trajectory the slice is taken. Yes there were slight alterations depending on what the particle properties were, smaller lighter particles would have less steep trajectories than heavier particles, but you could still get quite similar velocities and angles between multiple different particle properties just from taking the slices at different locations in the particle trajectories.
This ended up resulting in an idea of running all the various 4 injection heights, all 4 burning tree/stand objects, at once, then superimposing the pictures of the simulations side by side and upwind and downwind of the locations where the original injection locations were simulated. The result was that each and every single type of particle trajectory, upward and downward angles, speeds, were present at each slice, up to the height where the injection plumes stopped superimposing on one another. Holy crap, this meant that picking a specific choice of how embers show up from one simulation to another depends more on what burning vegetation configuration you wanted than most of the other variables: if it were continuous vegetation in height, side to side, and upwind and downwind, you would end up getting just a mix of all particle trajectories. A very interesting find, but not feasible to try to simulate all the various combinations, usually just the few that are of interest. Heck, it was already starting to be unfeasible to simulate all the combination of simulations needed when just looking at combining plots of particle trajectories split between two different simulation physics.
So, it also became apparent that when copying and pasting the sources next to each other upwind and downwind and to the sides in the flow, adding in more sources to fill all the heights in between, that all the sources blended together such that you got a mix of all particle sizes and all particle trajectories, up to the maximum height of the highest source. So kind of like an ember storm with embers coming in from the side and top of the domain in all sizes and all velocities and all directions. Some particles would reach the edge in the middle of their ascent, some would reach it as they get to the top of their path, some would reach it after starting to fall after reaching their peak values, you would see a combination of all of the paths. So it seemed justified to do an ember storm of some kind, maybe filtering out to look at specific sizes or specific velocities and angles.

The selection of the geometry and heights of the /burningTreeStands/ case injections were chosen to be representative of being the base of the plume at the tip of the crowning flame for the burning vegetation stands, the flame being a triangle slightly taller than wider going from the ground to a short ways above the tree, similar to the pictures describing farsite's spotting model other than that the plume is tilted with the wind. The sizes were assumed, and seemed to be good starting values, though they are totally abstract in their estimation, this is still a very idealized case. The  tilted plume width was assumed to be 1/3 the height of the tree crown, the tilted flame width at the top of the tree crown was assumed to be equal to 1/2 the height of the tree crown, the flame height above the tree crown to the base of the plume was assumed to be equal to 1/2 the height of the tree crown. This gave the flame a height of 3/2 the crown height. In the individual /constant/kinematicCloudProperties files, the position of the sources give a range of x to x height burning object, where the difference between the two heights is the height of the base stem below the crown, except for the 6 ft plume where it is assumed that it is a bush with negligible sized base. Burning objects are assumed to take 30 seconds to fully torch and burn, the plume shape and spread assumed to be occuring during the steady state portion of the tree torching process, which may or may not be true. A lot of assumptions were made in picking out these flame, tree base, tree crown height, flame height, flame tilt width, and plume tilt width values. These assumptions may or may not be correct physically, it was just a first pass of assumptions just to have something to work with without going to any literature other than the IBHS experiments, and it does at least seem to be a good starting spot for estimates of burning stand or tree flame and plume information.


The second particle simulations done were the /fullInletPatch/ cases, the original configuration being done with fence present, done at 20 mph, with 300 kg/m^3 particle density, with the larger sized embers. It was quickly discovered that this would likely be a very computationally expensive way to do ember injections for future cases with larger domain sizes, and something was off with the ember sizes and ember density that made the largest of embers fall to the ground even before reaching the fence. It was also quite difficult to see what was going on with particles that were going through the fence, it seemed like using a subset of particles instead of a full patch could be like filtering what particles were viewed by some kind of final falling trajectory or some other criteria. It was determined that maybe it would be easier to do a subset of the full inlet patch, offset some distance downwind from the inlet and upwind of the fence, to try to bring the injection closer to the region of interest so that the particles would reach the fence before they started to tilt so much to the earth, also with hopes that this would make it easier to see what was going on as particles passed through the fence.
It also quickly became apparent that there was little difference in results for the per time vs single time releases, so future simulations ended up being single time releases.


The third and final particle simulations done were the /sheetNearFence/ cases, the original configuration being done with fence present, done at 20 mph, with 300 kg/m^3 particle density, with the larger sized embers, quickly switching to a smaller set of embers and density. In the end, this was the style of injection used for the ember paper, but with smaller sizes and density, and an even more carefully chosen location and injection sheet size close to the fence. It became apparent that embers needed to start out with a bigger injection region, one that extended closer to the ground, to have better control of embers passing through all regions of the fence and fence wake, rather than just coming in at a different region of the fence and fence wake for a given change in ember trajectory.








This case was saved such that to run the particle simulations, you need to first run the wind simulation, then copy and paste the result files and mesh from the wind simulation to the particle simulation. Normally, this would mean copying and pasting the mesh from the latest time directory that has mesh files from the wind sim to the /0/ time directory of the particle sim, the mesh from /constant/ of the wind sim to the /constant/ of the particle sim, the /system/ mesh generation files from the wind sim to the /system/ folder of the particle sim, all the result files from the /latestTime/ time directory of the wind sim to the /0/ directory of the particle sim (make sure to not copy over the /uniform/ folder in this copy), the momentumTransport and transportProperties files from the /constant/ directory of the wind sim to the /constant/ directory of the particle sim copying and pasting the full "rho" entry from the transportProperties file to a new line of the transportProperties file renaming "rho" to be "rhoInf", copying the fvSchemes, fvSolution, and decomposeParDict files from the /system/ directory of the wind sim to the /system/ folder of the particle sim then modifying the fvSchemes file to be a ddtScheme of Euler instead of SteadyState, copying and pasting and then doing all necessary adjustments to change to the new simulation type and simulation times of the controlDict file from the /system/ folder of the wind sim to the /system/ folder of the particle sim, and adding the "g" and "kinematicCloudProperties" to the /constant/ folder of the particle simulation. But many of these files are already copied over, added, and modified to be what is required to run the particle simulation so that all that is left to do is to copy and paste the mesh files from the /constant/ directory of the wind sim to the /constant directory of the particle sim (in this case, this is the /polyMesh/ folder only, other cases have even more mesh files) and to copy and paste the final result /latestTime/ time directory files from the wind sim to the /0/ time directory of the particle simulation.

For particle simulations, the general practice is to run them once for the very first timestep, the end time and write timestep set to the simulation timestep, the log file of this one timestep simulation saved separately from the log file of the rest of the particle simulation, so that the initial injection of particles can be inspected. Then the write timestep is set to something reasonable that is frequently enough to see what is going on with the simulation, but not so small that you get an insane amount of data (which is very easy to do), the end time set to some large time, the simulation cut before the final end time at the write timestep just after the number of particles still in the domain matches the number of particles that have stuck, which is when the last particle has either left the domain or gone inactive. Unfortunately, the Lagrangian particle code has not been set to carry over the active and sticking information and so while you can potentially split the simulation into write timesteps to try to see what is going on more particularly, if you ever let the simulation stop and start again then you have to manually keep track of the number of stuck particles to know when the simulation is done, hence why separate log files for each particle simulation run is very helpful.







To run the case, use the following guide.


standard set of commands when in parallel for without fence wind simulations:
  blockMesh 2>&1 | tee blockMesh.log
  checkMesh 2>&1 | tee checkMesh.log
  decomposePar 2>&1 | tee decomposePar.log
  mpirun -np 3 simpleFoam -parallel 2>&1 | tee simpleFoam.log
  reconstructPar 2>&1 | tee reconstructPar.log

At the end after simulations, need to get the residuals:
  foamMonitor -l postProcessing/residuals/0/residuals.dat

At the end after simulations, need to do the sampling post processing for the python plots. 
Notice that I purposefully did NOT include the line "functions { #includeFunc singleGraph };" in controlDict,
as I just wanted data from the latest time, saves space on file since SS means only the last time matters for
plotting unless debugging. So I prefer post processing over run time processing for the plot sampling, to avoid
grabbing excess data. If you want data for all the timesteps, just drop the -latestTime argument.
command for without object cases
  simpleFoam -postProcess -func singleGraph -latestTime

To run the python script for the vertical profile plots, inlet vs outlet and some downwind profiles, in the folder with plot_vertical_profiles.py, run
  python plot_verticalProfiles.py
  python plot_inletOutletProfiles.py
You may need to adjust the singleGraph and python plot files for separate test cases.






standard set of commands when in parallel for with fence wind simulations:
  blockMesh 2>&1 | tee blockMesh.log
  checkMesh 2>&1 | tee checkMesh.log
  setFields 2>&1 | tee setFields.log
  decomposePar 2>&1 | tee decomposePar.log
  mpirun -np 3 myDragSimpleFoam -parallel 2>&1 | tee myDragSimpleFoam.log
  reconstructPar 2>&1 | tee reconstructPar.log

At the end after simulations, need to get the residuals:
  foamMonitor -l postProcessing/residuals/0/residuals.dat

At the end after simulations, need to do the sampling post processing for the python plots. 
Notice that I purposefully did NOT include the line "functions { #includeFunc singleGraph };" in controlDict,
as I just wanted data from the latest time, saves space on file since SS means only the last time matters for
plotting unless debugging. So I prefer post processing over run time processing for the plot sampling, to avoid
grabbing excess data. If you want data for all the timesteps, just drop the -latestTime argument.
command for with object cases
  myDragSimpleFoam -postProcess -func singleGraph -latestTime

To run the python script for the vertical profile plots, inlet vs outlet and some downwind profiles, in the folder with plot_vertical_profiles.py, run
  python plot_verticalProfiles.py
  python plot_inletOutletProfiles.py
You may need to adjust the singleGraph and python plot files for separate test cases.





For particle simulations, it turns out that decomposePar is not as fast, or at least it seems to only be for dealing with the eulerian wind field rather than dealing with the particle simulations. I used to do decomposePar for particle simulations and it took so much extra time to do reconstructPar to get the result back, that I found that doing it with just a single processor no decomposePar was the best way to go.
So here is the command to do particle simulations without decomposePar, the standard method I use now:
  particleFoam 2>&1 | tee particleFoam.log



Just in case, I left the decomposePar method here, just know that it didn't seem to be helpful when I tried it in the past. But I didn't get to crazy large domain cases yet either when I tried skipping this step. So if doing decomposePar for particle simulations, the first case needs decomposePar to distribute the appropriate wind field for the particle injection to the separate processor folders. This can be done with the following command:
  decomposePar 2>&1 | tee decomposePar.log
For all cases with the above commands already done, the following commands are used to run the particle simulations:
  mpirun -np 3 particleFoam -parallel 2>&1 | tee particleFoam.log
  reconstructPar 2>&1 | tee reconstructPar.log









